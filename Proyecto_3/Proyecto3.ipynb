{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1H8yG3hWR_Ef"
   },
   "source": [
    "<p><img alt=\"udeA logo\" height=\"150px\" src=\"https://github.com/freddyduitama/images/blob/master/logo.png?raw=true\" align=\"left\" hspace=\"50px\" vspace=\"0px\" style=\"width:107px;height:152px;\"></p>\n",
    "<h1><font color='#FFFFFFF'> <center>\n",
    "Proyecto 3: Filtros</center></font></h1>\n",
    "<h2><font color='#FFFFFFF'> <center>\n",
    "Proyecto 2024-02 </center></font></h2>\n",
    "<h3><font color='#FFFFFFF'> <center>María J. Ostos - Cristian Florez - Juan A. Sañudo</center></font></h3>\n",
    "<h3><font color='#FFFFFFF'> <center>\n",
    "2024 </center></font></h3>\n",
    "<font  face=\"Courier New\" size=\"3\">\n",
    "<p1><center> </center></p1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Del artículo: https://www.nature.com/articles/s41598-020-59821-7\n",
    "\n",
    "Consultar y explicar los dos métodos de reducción de ruido usados en el artículo: Robust LOESS y Non Local Means (10%), mostrar cómo se podrían implementar en Python (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Descargar los datos ECGData.zip de:\n",
    "https://figshare.com/collections/ChapmanECG/4560497/1\n",
    "\n",
    "De la base de datos extraer los registros que correspondan a bradicardia sinusal (SB Sinus Bradycardia) y fibrilación auricular (AFIB Atrial Fibrillation). Esta información está en el archivo Diagnostics.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6235,
     "status": "ok",
     "timestamp": 1730232750829,
     "user": {
      "displayName": "CRISTIAN FLOREZ CALDERON",
      "userId": "14203897282492324183"
     },
     "user_tz": 300
    },
    "id": "KIgaOMPf2dFi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy.fftpack import fft, ifft, fftfreq\n",
    "from scipy.signal import detrend\n",
    "from scipy.signal import welch\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "import os\n",
    "import pywt\n",
    "from scipy import stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos Diagnostics.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 3190,
     "status": "ok",
     "timestamp": 1730233041801,
     "user": {
      "displayName": "CRISTIAN FLOREZ CALDERON",
      "userId": "14203897282492324183"
     },
     "user_tz": 300
    },
    "id": "yYRVn3N06xhN",
    "outputId": "bdac8c45-569a-4cc8-9649-3e8c9490420e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>Beat</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>Gender</th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>QTCorrected</th>\n",
       "      <th>RAxis</th>\n",
       "      <th>TAxis</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QOnset</th>\n",
       "      <th>QOffset</th>\n",
       "      <th>TOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_27000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>RBBB TWC</td>\n",
       "      <td>85</td>\n",
       "      <td>MALE</td>\n",
       "      <td>117</td>\n",
       "      <td>234</td>\n",
       "      <td>114</td>\n",
       "      <td>356</td>\n",
       "      <td>496</td>\n",
       "      <td>81</td>\n",
       "      <td>-27</td>\n",
       "      <td>19</td>\n",
       "      <td>208</td>\n",
       "      <td>265</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_29000</td>\n",
       "      <td>SB</td>\n",
       "      <td>TWC</td>\n",
       "      <td>59</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>92</td>\n",
       "      <td>432</td>\n",
       "      <td>401</td>\n",
       "      <td>76</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>215</td>\n",
       "      <td>261</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180113_121940_44000</td>\n",
       "      <td>SB</td>\n",
       "      <td>NONE</td>\n",
       "      <td>66</td>\n",
       "      <td>MALE</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>96</td>\n",
       "      <td>456</td>\n",
       "      <td>427</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>219</td>\n",
       "      <td>267</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSE_20180112_120347_79000</td>\n",
       "      <td>SB</td>\n",
       "      <td>NONE</td>\n",
       "      <td>46</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>70</td>\n",
       "      <td>404</td>\n",
       "      <td>393</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>225</td>\n",
       "      <td>260</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MUSE_20180114_075026_69000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>TWC</td>\n",
       "      <td>80</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>98</td>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "      <td>360</td>\n",
       "      <td>459</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>215</td>\n",
       "      <td>252</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FileName Rhythm      Beat  PatientAge  Gender  \\\n",
       "0  MUSE_20180113_171327_27000   AFIB  RBBB TWC          85    MALE   \n",
       "1  MUSE_20180112_073319_29000     SB       TWC          59  FEMALE   \n",
       "3  MUSE_20180113_121940_44000     SB      NONE          66    MALE   \n",
       "5  MUSE_20180112_120347_79000     SB      NONE          46  FEMALE   \n",
       "6  MUSE_20180114_075026_69000   AFIB       TWC          80  FEMALE   \n",
       "\n",
       "   VentricularRate  AtrialRate  QRSDuration  QTInterval  QTCorrected  RAxis  \\\n",
       "0              117         234          114         356          496     81   \n",
       "1               52          52           92         432          401     76   \n",
       "3               53          53           96         456          427     34   \n",
       "5               57          57           70         404          393     38   \n",
       "6               98          86           74         360          459     69   \n",
       "\n",
       "   TAxis  QRSCount  QOnset  QOffset  TOffset  \n",
       "0    -27        19     208      265      386  \n",
       "1     42         8     215      261      431  \n",
       "3      3         9     219      267      447  \n",
       "5     24         9     225      260      427  \n",
       "6     83        17     215      252      395  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs=500\n",
    "\n",
    "ruta_diagnostics=\"./datos/Diagnostics.xlsx\"\n",
    "df_diagnostics = pd.read_excel(ruta_diagnostics)\n",
    "\n",
    "# Crear el nuevo dataframe filtrando por la columna 'Rhythm'\n",
    "datos_diagnostics = df_diagnostics[(df_diagnostics['Rhythm'] == 'SB') | (df_diagnostics['Rhythm'] == 'AFIB')]\n",
    "\n",
    "#Tamaño del nuevo dataframe\n",
    "datos_diagnostics.shape\n",
    "\n",
    "tiempo_diagnostics = np.arange(0, datos_diagnostics.shape[0]/fs,1/fs)\n",
    "\n",
    "datos_diagnostics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consultar que otros tipos de señales wavelet se pueden usar para el análisis de señales ECG y adaptar el código del filtro wavelet que se entrega en el curso de acuerdo a la consulta (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro Wavelet dado en el curso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wnoisest(coeff):\n",
    "    stdc = np.zeros((len(coeff),1));\n",
    "    for i in range(0,len(coeff)):\n",
    "        stdc[i] = (np.median(np.absolute(coeff[i])))/0.6745;\n",
    "    return stdc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(coeff):\n",
    "    Num_samples = 0;\n",
    "    for i in range(0,len(coeff)):\n",
    "        Num_samples = Num_samples + coeff[i].shape[0];\n",
    "    \n",
    "    thr = np.sqrt(2*(np.log(Num_samples)))\n",
    "    return thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wthresh(coeff):\n",
    "    y   = list();\n",
    "    s = wnoisest(coeff);\n",
    "    print(s)\n",
    "    thr = threshold(coeff)\n",
    "    print(thr)\n",
    "    for i in range(0,len(coeff)):\n",
    "        y.append(np.multiply(coeff[i],np.abs(coeff[i])>(thr*s[i])));\n",
    "    return thr,s,y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filt_wav(dato):\n",
    "    # data=datos_II[dato]\n",
    "    data=dato\n",
    "    LL = int(np.floor(np.log2(data.shape[0])));\n",
    "\n",
    "    data_wavelet = pywt.wavedec( data, 'db6', level=8 );\n",
    "    print(len(data_wavelet))\n",
    "\n",
    "    details = data_wavelet[1:]\n",
    "    print(len(details))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro wavelet para usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_wavelet(signal_data, wavelet='db4', nivel=4):\n",
    "    coeffs = pywt.wavedec(signal_data, wavelet, level=nivel)\n",
    "    umbral = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "    coeffs = [pywt.threshold(c, umbral, mode='soft') for c in coeffs]\n",
    "    return pywt.waverec(coeffs,wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Escoger 10 señales al azar y aplicar un flujo de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(selected_files):\n",
    "    # Diccionario para almacenar cada DataFrame y su columna 'II'\n",
    "    data_frames = {}\n",
    "    datos_II = {}\n",
    "    \n",
    "    # Iterar sobre los archivos en la lista\n",
    "    for i, file in enumerate(selected_files):\n",
    "        # Leer cada archivo y guardarlo en el diccionario con un nombre único\n",
    "        df = pd.read_csv(f\"./datos/ECGDataDenoised/{file}.csv\", delimiter=',', names=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'])\n",
    "        data_frames[f\"df{i+1}\"] = df\n",
    "        # datos_II[f\"datos_f{i+1}\"] = df[\"II\"]\n",
    "        datos_II[f\"{file}\"] = df[\"II\"]\n",
    "    \n",
    "    return data_frames, datos_II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar nombres de archivo en listas según el ritmo 'SB' y 'AFIB'\n",
    "sb_files = datos_diagnostics[datos_diagnostics['Rhythm'] == 'SB']['FileName'].tolist()\n",
    "afib_files = datos_diagnostics[datos_diagnostics['Rhythm'] == 'AFIB']['FileName'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número total de archivos a seleccionar\n",
    "n_seleccion = 10\n",
    "\n",
    "# Calcular la mitad para cada ritmo (o una distribución casi mitad y mitad si n_seleccion es impar)\n",
    "n_sb = n_seleccion // 2\n",
    "n_afib = n_seleccion - n_sb\n",
    "\n",
    "# Seleccionar aleatoriamente el número calculado de archivos de cada tipo\n",
    "selected_sb_files = random.sample(sb_files, min(n_sb, len(sb_files)))\n",
    "selected_afib_files = random.sample(afib_files, min(n_afib, len(afib_files)))\n",
    "\n",
    "# Combinar las selecciones de 'SB' y 'AFIB' en la lista final\n",
    "selected_files = selected_sb_files + selected_afib_files\n",
    "\n",
    "# Mezclar los archivos seleccionados para no tener un orden específico de 'SB' o 'AFIB'\n",
    "random.shuffle(selected_files)\n",
    "# Filtrar el DataFrame para obtener solo las filas de los archivos en selected_files\n",
    "selected_data = datos_diagnostics[datos_diagnostics['FileName'].isin(selected_files)]\n",
    "\n",
    "# Crear un diccionario con 'FileName' como clave y 'Rhythm' como valor para fácil acceso\n",
    "file_rhythm_dict = dict(zip(selected_data['FileName'], selected_data['Rhythm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames, datos_II = cargar_datos(selected_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MUSE_20180118_130405_09000', 'MUSE_20180112_120649_89000', 'MUSE_20180118_173302_02000', 'MUSE_20180114_132312_14000', 'MUSE_20180115_115742_25000', 'MUSE_20180118_132137_58000', 'MUSE_20180116_133618_66000', 'MUSE_20180114_121206_37000', 'MUSE_20180112_073749_76000', 'MUSE_20180113_133639_30000'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_II.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicar Wavelet \n",
    "for archivo in selected_files:\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(f\"../Proyecto_3/datos/ECGDataDenoised/{archivo}.csv\", delimiter=',', names=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'])\n",
    "    datos_II=df[\"II\"]\n",
    "    filtro_wavelet(datos_II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flujos de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flujo 1\n",
    "1. Filtro pasa-altas usando filtro IIR a 0.5 Hz. Justificar la elección de parámetros y si se usa FIR o IIR\n",
    "2. Filtro wavelet modificado del punto 3\n",
    "3. Filtrado pasabajas 50 Hz. Justificar la elección de parámetros y si se usa FIR o IIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flujo 1: Filtro pasa-altas, Filtro wavelet, Filtro pasabajas\n",
    "def flujo_1(data,fs = 1000 ):\n",
    "    # Paso 1: Filtro pasa-altas IIR a 0.5 Hz\n",
    "    cutoff = 0.5  # Frecuencia de corte en Hz\n",
    "    sos = signal.butter(4, cutoff, btype='highpass', fs=fs, output='sos')\n",
    "    data_highpass = signal.sosfilt(sos, data)\n",
    "    \n",
    "    # Paso 2: Filtro wavelet\n",
    "\n",
    "    wavelet='db4'\n",
    "    coeffs = pywt.wavedec(data_highpass, wavelet, level=4)\n",
    "    umbral = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "    coeffs = [pywt.threshold(c, umbral, mode='soft') for c in coeffs]\n",
    "    data_denoised = pywt.waverec(coeffs, wavelet)\n",
    " \n",
    "    \n",
    "    # Paso 3: Filtro pasabajas IIR a 50 Hz\n",
    "    cutoff = 50  # Frecuencia de corte en Hz\n",
    "    sos = signal.butter(4, cutoff, btype='lowpass', fs=fs, output='sos')\n",
    "    data_lowpass = signal.sosfilt(sos, data_denoised)\n",
    "    \n",
    "    return data_lowpass\n",
    "\n",
    "\n",
    "\n",
    "# def flujo_1(data,fs = 1000 ):\n",
    "#     # Paso 1: Filtro pasa-altas IIR a 0.5 Hz\n",
    "#     cutoff = 0.5  # Frecuencia de corte en Hz\n",
    "#     sos = signal.butter(4, cutoff, btype='highpass', fs=fs, output='sos')\n",
    "#     data_highpass = signal.sosfilt(sos, data)\n",
    "    \n",
    "#     # Paso 2: Filtro wavelet\n",
    "#     data_wavelet = pywt.wavedec(data_highpass, 'db6', level=8)\n",
    "#     details = data_wavelet[1:]\n",
    "#     thr, s, denoised_details = wthresh(details)  # Usa la función wthresh definida previamente\n",
    "#     data_wavelet_denoised = [data_wavelet[0]] + denoised_details\n",
    "#     data_denoised = pywt.waverec(data_wavelet_denoised, 'db6')\n",
    "    \n",
    "#     # Paso 3: Filtro pasabajas IIR a 50 Hz\n",
    "#     cutoff = 50  # Frecuencia de corte en Hz\n",
    "#     sos = signal.butter(4, cutoff, btype='lowpass', fs=fs, output='sos')\n",
    "#     data_lowpass = signal.sosfilt(sos, data_denoised)\n",
    "    \n",
    "#     return data_lowpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flujo 2\n",
    "1. Detrend\n",
    "2. Filtro wavelet modificado del punto 3\n",
    "3. Filtrado pasabajas 50 Hz. Justificar la elección de parámetros y si se usa FIR o IIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flujo 2: Detrend, Filtro wavelet, Filtro pasabajas\n",
    "def flujo_2(data,fs = 1000 ):\n",
    "    # Paso 1: Detrend\n",
    "    data_detrended = signal.detrend(data)\n",
    "    \n",
    "    # Paso 2: Filtro wavelet\n",
    "    wavelet='db4'\n",
    "    coeffs = pywt.wavedec(data_detrended, wavelet, level=4)\n",
    "    umbral = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "    coeffs = [pywt.threshold(c, umbral, mode='soft') for c in coeffs]\n",
    "    data_denoised = pywt.waverec(coeffs, wavelet)\n",
    "    \n",
    "    # Paso 3: Filtro pasabajas IIR a 50 Hz\n",
    "    cutoff = 50  # Frecuencia de corte en Hz\n",
    "    sos = signal.butter(4, cutoff, btype='lowpass', fs=fs, output='sos')\n",
    "    data_lowpass = signal.sosfilt(sos, data_denoised)\n",
    "    \n",
    "    return data_lowpass\n",
    "\n",
    "\n",
    "\n",
    "# # Flujo 2: Detrend, Filtro wavelet, Filtro pasabajas\n",
    "# def flujo_2(data,fs = 1000 ):\n",
    "#     # Paso 1: Detrend\n",
    "#     data_detrended = signal.detrend(data)\n",
    "    \n",
    "#     # Paso 2: Filtro wavelet\n",
    "#     data_wavelet = pywt.wavedec(data_detrended, 'db6', level=8)\n",
    "#     details = data_wavelet[1:]\n",
    "#     thr, s, denoised_details = wthresh(details)  # Usa la función wthresh definida previamente\n",
    "#     data_wavelet_denoised = [data_wavelet[0]] + denoised_details\n",
    "#     data_denoised = pywt.waverec(data_wavelet_denoised, 'db6')\n",
    "    \n",
    "#     # Paso 3: Filtro pasabajas IIR a 50 Hz\n",
    "#     cutoff = 50  # Frecuencia de corte en Hz\n",
    "#     sos = signal.butter(4, cutoff, btype='lowpass', fs=fs, output='sos')\n",
    "#     data_lowpass = signal.sosfilt(sos, data_denoised)\n",
    "    \n",
    "#     return data_lowpass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flujo 3\n",
    "1. Filtro pasa-altas usando filtro IIR a 0.5 Hz. Justificar la elección de parámetros y si se usa FIR o IIR\n",
    "2. Filtrado pasabajas 50 Hz. Justificar la elección de parámetros y si se usa FIR o IIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flujo 3: Filtro pasa-altas, Filtro pasabajas\n",
    "def flujo_3(data,fs = 1000 ):\n",
    "    # Paso 1: Filtro pasa-altas IIR a 0.5 Hz\n",
    "    cutoff = 0.5  # Frecuencia de corte en Hz\n",
    "    sos = signal.butter(4, cutoff, btype='highpass', fs=fs, output='sos')\n",
    "    data_highpass = signal.sosfilt(sos, data)\n",
    "    \n",
    "\n",
    "    # Paso 2: Filtro pasabajas IIR a 50 Hz\n",
    "    cutoff = 50  # Frecuencia de corte en Hz\n",
    "    sos = signal.butter(4, cutoff, btype='lowpass', fs=fs, output='sos')\n",
    "    data_lowpass = signal.sosfilt(sos, data_highpass)\n",
    "    \n",
    "    return data_lowpass\n",
    "\n",
    "\n",
    "\n",
    "# # Flujo 3: Filtro pasa-altas, Filtro pasabajas\n",
    "# def flujo_3(data,fs = 1000):\n",
    "#     # Paso 1: Filtro pasa-altas IIR a 0.5 Hz\n",
    "#     cutoff = 0.5  # Frecuencia de corte en Hz\n",
    "#     sos = signal.butter(4, cutoff, btype='highpass', fs=fs, output='sos')\n",
    "#     data_highpass = signal.sosfilt(sos, data)\n",
    "    \n",
    "#     # Paso 2: Filtro pasabajas IIR a 50 Hz\n",
    "#     cutoff = 50  # Frecuencia de corte en Hz\n",
    "#     sos = signal.butter(4, cutoff, btype='lowpass', fs=fs, output='sos')\n",
    "#     data_lowpass = signal.sosfilt(sos, data_highpass)\n",
    "    \n",
    "#     return data_lowpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ej aplicación de flujos\n",
    "# flujo_1(datos_II[\"MUSE_20180118_130405_09000\"],fs)\n",
    "\n",
    "#Aplicar Wavelet \n",
    "for archivo in selected_files[:2]:\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(f\"../Proyecto_3/datos/ECGDataDenoised/{archivo}.csv\", delimiter=',', names=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'])\n",
    "    datos_II=df[\"II\"]\n",
    "    flujo_3(datos_II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describir los resultados obtenidos y decidir si el resto del procesamiento se hace con el flujo 1, el flujo 2 o el flujo 3 (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecuaciones proyecto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grafica(tiempo,data,datos_process,nombre=\"Procesado\"):\n",
    "    \n",
    "    # Crear una figura con dos subplots en una fila\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15, 4))\n",
    "    # Graficar en el primer subplot\n",
    "    ax1.plot(tiempo,data, color=\"k\")\n",
    "    ax1.set_title('Original')\n",
    "    ax1.grid(True)\n",
    "    # Graficar en el segundo subplot\n",
    "    ax2.plot(tiempo,datos_process, color=\"r\", linestyle='-')\n",
    "    ax2.set_title(nombre)\n",
    "    ax2.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jSihit3J2dF8"
   },
   "outputs": [],
   "source": [
    "#Ecuación 1\n",
    "def detrend_n_deviation(data,tiempo):\n",
    "    datos_detrend=signal.detrend(data)\n",
    "    datos_deviation=np.mean((data-datos_detrend)**2)\n",
    "    return datos_detrend, datos_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1BXqwV8i2dF9"
   },
   "outputs": [],
   "source": [
    "# Ecuación 2\n",
    "def compress(signal):\n",
    "    xmin, xmax = np.min(signal), np.max(signal)\n",
    "    if xmin == xmax:\n",
    "        return signal  # Evitar dividir por cero si no hay rango\n",
    "    compressed_signal = (signal - xmin) / (xmax - xmin)\n",
    "    return np.array(compressed_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OfIvtf6p2dF-"
   },
   "outputs": [],
   "source": [
    "#Ecuaciones 3 y 4\n",
    "def bispectrum_bicoherence(signal, fs, segment):\n",
    "    # Dividir la señal en segmentos de longitud nfft\n",
    "    segmentos = [signal[i:i + segment] for i in range(0, len(signal) - segment + 1, segment)]\n",
    "    segmentos = np.array(segmentos)\n",
    "    num_segmentos = segmentos.shape[0]\n",
    "\n",
    "    # Aplicar la Transformada de Fourier a cada segmento\n",
    "    fft_segmentos = np.fft.fft(segmentos, n=segment, axis=1)[:, :segment // 2]\n",
    "\n",
    "    # Inicializar matrices para el bispectro y la bicoherencia\n",
    "    bispectro = np.zeros((segment // 2, segment // 2), dtype=complex)\n",
    "    acumulado = np.zeros((segment // 2, segment // 2), dtype=complex)\n",
    "\n",
    "    # Calcular el bispectro y el valor acumulado para la bicoherencia\n",
    "    for k in range(num_segmentos):\n",
    "        S = fft_segmentos[k, :]\n",
    "        for f1 in range(segment // 2):\n",
    "            for f2 in range(f1, segment // 2 - f1):\n",
    "                f3 = f1 + f2\n",
    "                if f3 < segment // 2:  # Evitar exceder los límites del espectro\n",
    "                    producto = S[f1] * S[f2] * np.conj(S[f3])\n",
    "                    bispectro[f1, f2] += producto\n",
    "                    acumulado[f1, f2] += np.abs(producto)\n",
    "\n",
    "    # Normalizar el bispectro para obtener la bicoherencia\n",
    "    bicoherencia = np.abs(bispectro) / acumulado\n",
    "\n",
    "    # Aplicar simetría a la matriz de bicoherencia\n",
    "    return bispectro, bicoherencia\n",
    "\n",
    "\n",
    "def aplicar_simetria(matriz):\n",
    "    matriz_simetrica = np.zeros_like(matriz)\n",
    "    for f1 in range(matriz.shape[0]):\n",
    "        for f2 in range(f1, matriz.shape[1] - f1):\n",
    "            matriz_simetrica[f1, f2] = matriz[f1, f2]\n",
    "    return matriz_simetrica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "8ZUXFFSc2dF_"
   },
   "outputs": [],
   "source": [
    "# Para cada señal extraer la frecuencia que contiene la máxima potencia y Gráfiquela \n",
    "def obtener_frecuencia_maxima_potencia(df, fs=1000):\n",
    "    \"\"\"\n",
    "    Calcula la frecuencia con la máxima potencia en el espectro de una señal utilizando Welch.\n",
    "\n",
    "    Parámetros:\n",
    "    df : pd.DataFrame - DataFrame que contiene la columna 'signal' con la señal.\n",
    "    fs : int - Frecuencia de muestreo de la señal (en Hz). Ajustar según los datos reales.\n",
    "\n",
    "    Retorna:\n",
    "    frecuencia_max : float - La frecuencia con la máxima potencia.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que la columna 'signal' existe en el dataframe\n",
    "    # if 'II' not in df.columns:\n",
    "    #     raise ValueError(\"El DataFrame debe contener una columna llamada 'signal'.\")\n",
    "\n",
    "    # Calcular la densidad espectral de potencia utilizando Welch\n",
    "    frecuencias, potencia = welch(df, fs=fs)\n",
    "\n",
    "    # Encontrar la frecuencia con la máxima potencia\n",
    "    indice_max_potencia = potencia.argmax()\n",
    "    frecuencia_max = frecuencias[indice_max_potencia]\n",
    "\n",
    "    return frecuencia_max\n",
    "\n",
    "# # Función para calcular la frecuencia de máxima potencia\n",
    "# def max_power_frequency(signal, fs):\n",
    "#     # Calcular la transformada de Fourier del señal\n",
    "#     fft_vals = np.fft.fft(signal)\n",
    "#     # Mantener solo la mitad de los valores (espectro positivo)\n",
    "#     fft_magnitude = np.abs(fft_vals[:len(fft_vals)//2])\n",
    "#     # Calcular las frecuencias correspondientes\n",
    "#     frequencies = np.fft.fftfreq(len(signal), d=1/fs)[:len(fft_vals)//2]\n",
    "#     # Calcular la potencia en el dominio de la frecuencia\n",
    "#     power_spectrum = fft_magnitude**2\n",
    "#     # Encontrar el índice de la frecuencia con máxima potencia\n",
    "#     max_power_idx = np.argmax(power_spectrum)\n",
    "#     # Obtener la frecuencia de máxima potencia y el valor de la potencia máxima\n",
    "#     max_frequency = round(frequencies[max_power_idx], 5)\n",
    "#     max_power_value = power_spectrum[max_power_idx]\n",
    "#     # Graficar la magnitud de la transformada de Fourier y marcar la frecuencia de máxima potencia\n",
    "#     plt.figure()\n",
    "#     plt.plot(frequencies, fft_magnitude)\n",
    "#     plt.axvline(x=max_frequency, color='k', linestyle='--', label=f'Máxima Frecuencia: {max_frequency} Hz')\n",
    "#     plt.legend()\n",
    "\n",
    "#     return max_frequency, max_power_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a04Wh7u2dGA"
   },
   "source": [
    "5. Para cada señal sumar el número de frecuencias que son significativas para bicoherencia (cuales tienen un valor superior a ![image](https://github.com/user-attachments/assets/636a4170-c3f7-4789-9100-f2a0ce0033c3) ) (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4OWnXE1b2dGB"
   },
   "outputs": [],
   "source": [
    "# Función para sumar las frecuencias significativas en bicoherencia\n",
    "def significant_frequencies_bicoherence(bicoherence, N):\n",
    "    threshold = np.sqrt(9.2 / (2 * N))\n",
    "    significant_frequencies = np.sum(bicoherence > threshold)\n",
    "    return significant_frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1p3Wmut2dGC"
   },
   "source": [
    "6. Crear una rutina que aplique sobre todos los archivos de la base de datos las rutina 3 al 5 y almacene los resultados en un dataframe donde se pueda registro, tipo de patología y el frecuencia de máxima potencia (fMP) y suma de frecuencias significativas en bicoherencia (sFSB):\n",
    "\n",
    "| Registro | Estado | fMP | sFSB  |\n",
    "| --- | --- | --- | --- |\n",
    "| --- | --- | --- | --- |\n",
    "| --- | --- | --- | --- |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "S8gQVqy22dGC"
   },
   "outputs": [],
   "source": [
    "def signal_process(datos,tiempo,fs):\n",
    "    print(\"Aplicando detrend\")\n",
    "    data_detrended=detrend_n_deviation(datos,tiempo)\n",
    "    print(f'La desviación es {data_detrended[1]}')\n",
    "    # Grafica(tiempo,datos,data_detrended[0],nombre=\"Detrended\")\n",
    "\n",
    "    print(\"Aplicando compress\")\n",
    "    data_compressed=compress(data_detrended[0])\n",
    "    # Grafica(tiempo,data_detrended[0],data_compressed,\"Compressed\")\n",
    "\n",
    "    print(\"Aplicando biespectro y bicoherencia\")\n",
    "    bisp_Bic=bispectrum_bicoherence(data_compressed,fs,1000)\n",
    "    # Grafica(datos[:len(bisp_Bic[0])],data_compressed[:len(bisp_Bic[0])],bisp_Bic[0],\"bispectrum and bicoherence\")\n",
    "    # Grafica(tiempo[:len(bisp_Bic[0])],data_compressed[:len(bisp_Bic[0])],bisp_Bic[0],\"bispectrum\")\n",
    "    # Calcular el bispectro\n",
    "\n",
    "    bisp_Bic = bispectrum_bicoherence(datos_II, fs, 1000)\n",
    "    bisp_Bic= aplicar_simetria(bisp_Bic[1])\n",
    "    # Graficar el bicoherence\n",
    "    # plt.figure(figsize=(8, 5))\n",
    "    # plt.imshow(np.abs(bisp_Bic), extent=(0, 20, 0, 10), aspect='auto', origin='lower', cmap='viridis')\n",
    "    # plt.colorbar(label='Magnitud de bicoherencia')\n",
    "    # plt.xlabel('Frecuencia f1 (Hz)')\n",
    "    # plt.ylabel('Frecuencia f2 (Hz)')\n",
    "    # plt.title('Bicoherencia Simétrica')\n",
    "    # plt.show()\n",
    "\n",
    "    print(\"calculando la máxima potencia\")\n",
    "    max_p=obtener_frecuencia_maxima_potencia(datos,fs)\n",
    "    print(f'La máxima potencia es {[max_p]}')\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # # plt.semilogy(max_p[1], max_p[2], label='Densidad Espectral de Potencia')\n",
    "    # plt.axvline(max_p[0], color='r', linestyle='--', label=f'Máxima Frecuencia: {max_p[0]:.2f} Hz')\n",
    "\n",
    "    # plt.plot(max_p[1], max_p[2])\n",
    "    # plt.xlim([0,20])\n",
    "\n",
    "    \n",
    "    # plt.title('Densidad Espectral de Potencia')\n",
    "    # plt.xlabel('Frecuencia [Hz]')\n",
    "    # plt.ylabel('Densidad Espectral [V^2/Hz]')\n",
    "    # plt.legend()\n",
    "    # plt.grid()\n",
    "    # plt.show()\n",
    "\n",
    "    # print(\"calculando Frecuencias significativas\")\n",
    "    # sig_f=significant_frequencies_bicoherence(bisp_Bic[1],len(bisp_Bic[1]))\n",
    "    # print(f'Frecuencias significativas para bicoherencia: {sig_f} Hz \\n')\n",
    "    \n",
    "    # return data_detrended, data_compressed, bisp_Bic, max_p, sig_f\n",
    "    return data_detrended, data_compressed, bisp_Bic, max_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQRl3PAG2dGE"
   },
   "source": [
    "### Aplicar procesado a señal de derivada II por metodo proyecto 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OJOJSi-2dGF"
   },
   "source": [
    "7. Para las señales de análisis del punto 2 aplicar las rutinas del punto 3 al 5 y hacer un informe que permita evidenciar las diferencias entre las señales SB y AFIB utilizando las herramientas de estadística descriptiva (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JXM2C8mB2dGG",
    "outputId": "ece0af9e-c093-4943-b55f-77ca4ee84a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando detrend\n",
      "La desviación es 27.81953570693658\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(7.8125)]\n",
      "Aplicando detrend\n",
      "La desviación es 2330.9675138779708\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\1847125809.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_resultados = pd.concat([df_resultados,\n",
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(3.90625)]\n",
      "Aplicando detrend\n",
      "La desviación es 3299.240163107669\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(1.953125)]\n",
      "Aplicando detrend\n",
      "La desviación es 1821.4547680896264\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(7.8125)]\n",
      "Aplicando detrend\n",
      "La desviación es 2402.619282584272\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(3.90625)]\n",
      "Aplicando detrend\n",
      "La desviación es 3485.9669576883\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(1.953125)]\n",
      "Aplicando detrend\n",
      "La desviación es 107.35243249781126\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(3.90625)]\n",
      "Aplicando detrend\n",
      "La desviación es 1685.2868485143974\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(3.90625)]\n",
      "Aplicando detrend\n",
      "La desviación es 127.85626965481939\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(1.953125)]\n",
      "Aplicando detrend\n",
      "La desviación es 1349.1182037329459\n",
      "Aplicando compress\n",
      "Aplicando biespectro y bicoherencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Temp\\ipykernel_16448\\3190863204.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  bicoherencia = np.abs(bispectro) / acumulado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculando la máxima potencia\n",
      "La máxima potencia es [np.float64(1.953125)]\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame vacío para almacenar los resultados\n",
    "# df_resultados = pd.DataFrame(columns=[\"Registro\", \"Estado\", \"fMP\", \"sFSB\"])\n",
    "df_resultados = pd.DataFrame(columns=[\"Registro\", \"Estado\", \"fMP\"])\n",
    "# ruta_carpeta=\"../Proyecto_3/datos/\"\n",
    "# rut=\".csv\"\n",
    "\n",
    "for archivo in selected_files:\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(f\"../Proyecto_3/datos/ECGDataDenoised/{archivo}.csv\", delimiter=',', names=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'])\n",
    "    datos_II=df[\"II\"]\n",
    "    tiempo = np.arange(0, datos_II.shape[0]/fs,1/fs)\n",
    "\n",
    "# Obtener el nombre del sujeto (sin extensión .csv)\n",
    "    nombre_sujeto = archivo[:-4] #Registro\n",
    "\n",
    "# Procesar los archivos\n",
    "    resultados_proceso=signal_process(datos_II,tiempo,fs)\n",
    "\n",
    "    estado = file_rhythm_dict[archivo] #Estado\n",
    "\n",
    "    F_max=resultados_proceso[3] #fMP\n",
    "    \n",
    "    # F_sig=resultados_proceso[4] #sFSB\n",
    "\n",
    "    # df_resultados = pd.concat([df_resultados,\n",
    "    #                     pd.DataFrame({'Registro': nombre_sujeto,\n",
    "    #                                     'Estado': estado,\n",
    "    #                                     'fMP': F_max,\n",
    "    #                                     'sFSB': F_sig},\n",
    "    #                                 index=[0])\n",
    "    #                     ],\n",
    "    #                     ignore_index=True)\n",
    "    \n",
    "    df_resultados = pd.concat([df_resultados,\n",
    "                    pd.DataFrame({'Registro': nombre_sujeto,\n",
    "                                    'Estado': estado,\n",
    "                                    'fMP': F_max},\n",
    "                                index=[0])\n",
    "                    ],\n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "x91-e6nl2dGJ",
    "outputId": "6261c93c-cf0d-40ea-ca1d-20cf91fbb854"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registro</th>\n",
       "      <th>Estado</th>\n",
       "      <th>fMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180118_130405_0</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>7.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_120649_8</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>3.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180118_173302_0</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>1.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180114_132312_1</td>\n",
       "      <td>SB</td>\n",
       "      <td>7.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180115_115742_2</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>3.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSE_20180118_132137_5</td>\n",
       "      <td>SB</td>\n",
       "      <td>1.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MUSE_20180116_133618_6</td>\n",
       "      <td>SB</td>\n",
       "      <td>3.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MUSE_20180114_121206_3</td>\n",
       "      <td>SB</td>\n",
       "      <td>3.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MUSE_20180112_073749_7</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>1.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MUSE_20180113_133639_3</td>\n",
       "      <td>SB</td>\n",
       "      <td>1.953125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Registro Estado       fMP\n",
       "0  MUSE_20180118_130405_0   AFIB  7.812500\n",
       "1  MUSE_20180112_120649_8   AFIB  3.906250\n",
       "2  MUSE_20180118_173302_0   AFIB  1.953125\n",
       "3  MUSE_20180114_132312_1     SB  7.812500\n",
       "4  MUSE_20180115_115742_2   AFIB  3.906250\n",
       "5  MUSE_20180118_132137_5     SB  1.953125\n",
       "6  MUSE_20180116_133618_6     SB  3.906250\n",
       "7  MUSE_20180114_121206_3     SB  3.906250\n",
       "8  MUSE_20180112_073749_7   AFIB  1.953125\n",
       "9  MUSE_20180113_133639_3     SB  1.953125"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resultados.to_excel(\"Dataframe_P2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = datos_diagnostics['FileName'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame vacío para almacenar los resultados\n",
    "# df_resultados = pd.DataFrame(columns=[\"Registro\", \"Estado\", \"fMP\", \"sFSB\"])\n",
    "df_resultados = pd.DataFrame(columns=[\"Registro\", \"Estado\", \"fMP\"])\n",
    "# ruta_carpeta=\"../Proyecto_3/datos/\"\n",
    "# rut=\".csv\"\n",
    "\n",
    "for archivo in all_files:\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(f\"../Proyecto_3/datos/ECGDataDenoised/{archivo}.csv\", delimiter=',', names=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'])\n",
    "    datos_II=df[\"II\"]\n",
    "    tiempo = np.arange(0, datos_II.shape[0]/fs,1/fs)\n",
    "\n",
    "# Obtener el nombre del sujeto (sin extensión .csv)\n",
    "    nombre_sujeto = archivo[:-4] #Registro\n",
    "\n",
    "# Procesar los archivos\n",
    "    resultados_proceso=signal_process(datos_II,tiempo,fs)\n",
    "\n",
    "    estado = file_rhythm_dict[archivo] #Estado\n",
    "\n",
    "    F_max=resultados_proceso[3] #fMP\n",
    "    \n",
    "    # F_sig=resultados_proceso[4] #sFSB\n",
    "\n",
    "    # df_resultados = pd.concat([df_resultados,\n",
    "    #                     pd.DataFrame({'Registro': nombre_sujeto,\n",
    "    #                                     'Estado': estado,\n",
    "    #                                     'fMP': F_max,\n",
    "    #                                     'sFSB': F_sig},\n",
    "    #                                 index=[0])\n",
    "    #                     ],\n",
    "    #                     ignore_index=True)\n",
    "    \n",
    "    df_resultados_all = pd.concat([df_resultados,\n",
    "                    pd.DataFrame({'Registro': nombre_sujeto,\n",
    "                                    'Estado': estado,\n",
    "                                    'fMP': F_max},\n",
    "                                index=[0])\n",
    "                    ],\n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.to_excel(\"Dataframe_P2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.17636665,   1.30513762,   4.65246662, ..., -41.26171485,\n",
       "       -39.07229233, -36.15797145])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tMyEoad2dGL"
   },
   "source": [
    "8. Indicar si hay o no diferencias estadísticas entre las características espectrales del punto 4 y 5 para las dos poblaciones de estudio (5%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2OCRwwN2dGL"
   },
   "source": [
    "Prueba de Normalidad\n",
    "\n",
    "Hipótesis nula (Ho): Los datos recolectados del ECG no distribuyen normal\n",
    "\n",
    "Hipotesis alternativa (H1): Los datos distribuyen de manera normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNx3lF_C2dGM",
    "outputId": "56fd763d-d2e7-4128-b04a-1f76a627c751"
   },
   "outputs": [],
   "source": [
    "#Prueba de Normalidad\n",
    "alpha=0.05 #Valor de significancia de 5%\n",
    "cols=df_resultados.columns[2:]\n",
    "for i in cols:\n",
    "    [statistic,pvalue]=stats.normaltest(df_resultados[i])\n",
    "    if pvalue > alpha:\n",
    "        print(f'la columna {i} distribuye normal')\n",
    "    else:\n",
    "        print(f'la columna {i} no distribuye normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8qG4qmb2dGP"
   },
   "source": [
    "Prueba Homocedasticidad  \n",
    "Hipótesis nula (Ho): Los varianza de los datos recolectados del ECG no son significativamente diferentes\n",
    "\n",
    "Hipotesis alternativa (H1): La varianza de los datos son significativamente diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34Q7RIoo2dGQ",
    "outputId": "1f5ee795-6e81-4868-9830-e5def6567b7e"
   },
   "outputs": [],
   "source": [
    "#Prueba Homocedasticidad\n",
    "# [statistic,pvalue]=stats.levene(ciclos[2],ciclos[3],ciclos[13],ciclos[14])\n",
    "[statistic,pvalue]=stats.levene(df_resultados[\"fMP\"],df_resultados[\"sFSB\"])\n",
    "print(f'Valor p: {pvalue} \\n')\n",
    "if pvalue > alpha:\n",
    "    print('Cumple supuesto de homocedasticidad') #Varianzas no son significativamente diferentes\n",
    "else:\n",
    "    print('No cumple supuesto de homocedasticidad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iamVkEM2dGT"
   },
   "source": [
    "Prueba Mann-Whitney\n",
    "\n",
    "Hipótesis nula (Ho): No hay diferencia entre la frecuencia significativa en bicoherencia entre pacientes con bradicardia sinusal (SB) y fibrilación auricular (AFIB)\n",
    "Hipotesis alternativa (H1): Si hay diferencia de la frecuencia significativa en bicoherencia entre pacientes con bradicardia sinusal (SB) y fibrilación auricular (AFIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3prJreBw2dGU",
    "outputId": "8a512755-e311-40d0-ee74-89b76ac9ea62"
   },
   "outputs": [],
   "source": [
    "#Prueba Mann-Whitney\n",
    "df_resultados[\"sFSB\"]= pd.to_numeric(df_resultados[\"sFSB\"], errors='coerce')\n",
    "grupo1 = df_resultados[\"fMP\"]\n",
    "grupo2 = df_resultados[\"sFSB\"]\n",
    "[statistic,pvalue]=stats.mannwhitneyu(grupo1,grupo2)\n",
    "if pvalue < alpha:\n",
    "    print('Existe diferencia significativa entre fMP y sFSB ')\n",
    "else:\n",
    "    print('No existe diferencia significativa entre fMP y sFSB')\n",
    "print(f'Valor p: {pvalue} \\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
