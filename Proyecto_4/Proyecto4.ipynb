{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1H8yG3hWR_Ef"
   },
   "source": [
    "<p><img alt=\"udeA logo\" height=\"150px\" src=\"https://github.com/freddyduitama/images/blob/master/logo.png?raw=true\" align=\"left\" hspace=\"50px\" vspace=\"0px\" style=\"width:107px;height:152px;\"></p>\n",
    "<h1><font color='#FFFFFFF'> <center>\n",
    "Proyecto 4</center></font></h1>\n",
    "<h2><font color='#FFFFFFF'> <center>\n",
    "Proyecto 2024-02 </center></font></h2>\n",
    "<h3><font color='#FFFFFFF'> <center>María J. Ostos - Cristian Florez - Juan A. Sañudo</center></font></h3>\n",
    "<h3><font color='#FFFFFFF'> <center>\n",
    "2024 </center></font></h3>\n",
    "<font  face=\"Courier New\" size=\"3\">\n",
    "<p1><center> </center></p1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Revisión teórica. Del artículo:\n",
    "https://www.nature.com/articles/s41598-020-59821-7\n",
    "\n",
    "Hacer un resumen de la sección extracción de caracteríticas (Features extraction) y discutir desde el artículo u otras referencias como se hace cuando desaparecen ciertas formas de ondas en el complejo PQRS debido a alguna enfermedad (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Base de datos. Del proyecto pasado hay dos opciones de base de datos, la filtrada por los autores o la filtrada en el proyecto 3. De acuerdo a los resultados del proyecto 3 usar la mejor base de datos y justificar la selección\n",
    "De la base de datos extraer los registros que correspondan a bradicardia sinusal (SB Sinus Bradycardia) y fibrilación auricular (AFIB Atrial Fibrillation). Esta información está en el archivo Diagnostics.xlsx De estos registros los análisis para el presente proyecto deben hacerse en la derivación II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6235,
     "status": "ok",
     "timestamp": 1730232750829,
     "user": {
      "displayName": "CRISTIAN FLOREZ CALDERON",
      "userId": "14203897282492324183"
     },
     "user_tz": 300
    },
    "id": "KIgaOMPf2dFi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import detrend, welch, butter, filtfilt\n",
    "import pywt\n",
    "import random\n",
    "import warnings\n",
    "import neurokit2 as nk\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#MLP\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#CNN\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "#LSTM\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Para warnings de tipo UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)  # Para warnings de tipo RuntimeWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos Diagnostics.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 3190,
     "status": "ok",
     "timestamp": 1730233041801,
     "user": {
      "displayName": "CRISTIAN FLOREZ CALDERON",
      "userId": "14203897282492324183"
     },
     "user_tz": 300
    },
    "id": "yYRVn3N06xhN",
    "outputId": "bdac8c45-569a-4cc8-9649-3e8c9490420e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>Beat</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>Gender</th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>QTCorrected</th>\n",
       "      <th>RAxis</th>\n",
       "      <th>TAxis</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QOnset</th>\n",
       "      <th>QOffset</th>\n",
       "      <th>TOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_27000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>RBBB TWC</td>\n",
       "      <td>85</td>\n",
       "      <td>MALE</td>\n",
       "      <td>117</td>\n",
       "      <td>234</td>\n",
       "      <td>114</td>\n",
       "      <td>356</td>\n",
       "      <td>496</td>\n",
       "      <td>81</td>\n",
       "      <td>-27</td>\n",
       "      <td>19</td>\n",
       "      <td>208</td>\n",
       "      <td>265</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_29000</td>\n",
       "      <td>SB</td>\n",
       "      <td>TWC</td>\n",
       "      <td>59</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>92</td>\n",
       "      <td>432</td>\n",
       "      <td>401</td>\n",
       "      <td>76</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>215</td>\n",
       "      <td>261</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180113_121940_44000</td>\n",
       "      <td>SB</td>\n",
       "      <td>NONE</td>\n",
       "      <td>66</td>\n",
       "      <td>MALE</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>96</td>\n",
       "      <td>456</td>\n",
       "      <td>427</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>219</td>\n",
       "      <td>267</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSE_20180112_120347_79000</td>\n",
       "      <td>SB</td>\n",
       "      <td>NONE</td>\n",
       "      <td>46</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>70</td>\n",
       "      <td>404</td>\n",
       "      <td>393</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>225</td>\n",
       "      <td>260</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MUSE_20180114_075026_69000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>TWC</td>\n",
       "      <td>80</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>98</td>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "      <td>360</td>\n",
       "      <td>459</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>215</td>\n",
       "      <td>252</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FileName Rhythm      Beat  PatientAge  Gender  \\\n",
       "0  MUSE_20180113_171327_27000   AFIB  RBBB TWC          85    MALE   \n",
       "1  MUSE_20180112_073319_29000     SB       TWC          59  FEMALE   \n",
       "3  MUSE_20180113_121940_44000     SB      NONE          66    MALE   \n",
       "5  MUSE_20180112_120347_79000     SB      NONE          46  FEMALE   \n",
       "6  MUSE_20180114_075026_69000   AFIB       TWC          80  FEMALE   \n",
       "\n",
       "   VentricularRate  AtrialRate  QRSDuration  QTInterval  QTCorrected  RAxis  \\\n",
       "0              117         234          114         356          496     81   \n",
       "1               52          52           92         432          401     76   \n",
       "3               53          53           96         456          427     34   \n",
       "5               57          57           70         404          393     38   \n",
       "6               98          86           74         360          459     69   \n",
       "\n",
       "   TAxis  QRSCount  QOnset  QOffset  TOffset  \n",
       "0    -27        19     208      265      386  \n",
       "1     42         8     215      261      431  \n",
       "3      3         9     219      267      447  \n",
       "5     24         9     225      260      427  \n",
       "6     83        17     215      252      395  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs=500\n",
    "\n",
    "# ruta_diagnostics= r\"C:\\Users\\Lenovo a9 w10\\Documents\\LabBiosenales\\Proyecto_2/Diagnostics.xlsx\"\n",
    "ruta_diagnostics=\"../Proyecto_3/datos/Diagnostics.xlsx\"\n",
    "df_diagnostics = pd.read_excel(ruta_diagnostics)\n",
    "\n",
    "# Crear el nuevo dataframe filtrando por la columna 'Rhythm'\n",
    "datos_diagnostics = df_diagnostics[(df_diagnostics['Rhythm'] == 'SB') | (df_diagnostics['Rhythm'] == 'AFIB')]\n",
    "\n",
    "#Tamaño del nuevo dataframe\n",
    "datos_diagnostics.shape\n",
    "\n",
    "tiempo_diagnostics = np.arange(0, datos_diagnostics.shape[0]/fs,1/fs)\n",
    "\n",
    "datos_diagnostics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FileName', 'Rhythm', 'Beat', 'PatientAge', 'Gender', 'VentricularRate',\n",
       "       'AtrialRate', 'QRSDuration', 'QTInterval', 'QTCorrected', 'RAxis',\n",
       "       'TAxis', 'QRSCount', 'QOnset', 'QOffset', 'TOffset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_diagnostics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar nombres de archivo en listas según el ritmo 'SB' y 'AFIB'\n",
    "sb_files = datos_diagnostics[datos_diagnostics['Rhythm'] == 'SB']['FileName'].tolist()\n",
    "afib_files = datos_diagnostics[datos_diagnostics['Rhythm'] == 'AFIB']['FileName'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(selected_files,ruta): #Ruta 1 sin filtrar, 2 para filtrados\n",
    "    # Diccionario para almacenar cada DataFrame y su columna 'II'\n",
    "    data_frames = {}\n",
    "    datos_II = {}\n",
    "    \n",
    "    # Iterar sobre los archivos en la lista\n",
    "    for i, file in enumerate(selected_files):\n",
    "        if ruta==1:\n",
    "            df = pd.read_csv(f\"../Proyecto_3/datos/ECGData/ECGData/{file}.csv\", delimiter=',', names=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'])\n",
    "        elif ruta==2:\n",
    "            df = pd.read_csv(f\"../Proyecto_3/datos/ECGDataDenoised/{file}.csv\", delimiter=',', names=['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'])\n",
    "        data_frames[f\"df{i+1}\"] = df\n",
    "        # datos_II[f\"datos_f{i+1}\"] = df[\"II\"]\n",
    "        datos_II[f\"{file}\"] = df[\"II\"]\n",
    "    \n",
    "    return data_frames, datos_II\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Herramientas computacionales. Hacer un minitutorial del uso de la herramienta NeuroKit (https://neuropsychology.github.io/NeuroKit/index.html) orientado al análisis de señales ECG (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Escoger diferentes señales de la base de datos del punto 2 y aplicar el tutorial del punto 3 (5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Codigo para pruebas con n sujetos\n",
    "\n",
    "# Número total de archivos a seleccionar\n",
    "n_seleccion = 5\n",
    "\n",
    "# Calcular la mitad para cada ritmo (o una distribución casi mitad y mitad si n_seleccion es impar)\n",
    "n_sb = n_seleccion // 2\n",
    "n_afib = n_seleccion - n_sb\n",
    "\n",
    "# Seleccionar aleatoriamente el número calculado de archivos de cada tipo\n",
    "selected_sb_files = random.sample(sb_files, min(n_sb, len(sb_files)))\n",
    "selected_afib_files = random.sample(afib_files, min(n_afib, len(afib_files)))\n",
    "\n",
    "# Combinar las selecciones de 'SB' y 'AFIB' en la lista final\n",
    "selected_files = selected_sb_files + selected_afib_files\n",
    "\n",
    "# Mezclar los archivos seleccionados para no tener un orden específico de 'SB' o 'AFIB'\n",
    "random.shuffle(selected_files)\n",
    "# Filtrar el DataFrame para obtener solo las filas de los archivos en selected_files\n",
    "selected_data = datos_diagnostics[datos_diagnostics['FileName'].isin(selected_files)]\n",
    "\n",
    "# Crear un diccionario con 'FileName' como clave y 'Rhythm' como valor para fácil acceso\n",
    "file_rhythm_dict = dict(zip(selected_data['FileName'], selected_data['Rhythm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cargan los datos\n",
    "all_files = datos_diagnostics['FileName'].tolist()\n",
    "dfs1,datos_II_ecg=cargar_datos(selected_files,1)\n",
    "sujetos=datos_II_ecg.keys()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MUSE_20180113_171327_27000', 'MUSE_20180112_073319_29000', 'MUSE_20180113_121940_44000', 'MUSE_20180112_120347_79000', 'MUSE_20180114_075026_69000', 'MUSE_20180114_075128_92000', 'MUSE_20180118_174026_42000', 'MUSE_20180115_125443_25000'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para obtener solo las filas de los archivos en selected_files\n",
    "selected_data_all = datos_diagnostics[datos_diagnostics['FileName'].isin(all_files)]\n",
    "\n",
    "# Crear un diccionario con 'FileName' como clave y 'Rhythm' como valor para fácil acceso\n",
    "file_rhythm_all = dict(zip(selected_data_all['FileName'], selected_data_all['Rhythm']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Con las características que extrae el neurokit y las discutidas en el punto 1 generar un conjunto de características para el presente trabajo. Incluir la característica de frecuencia de potencia máxima del Proyecto 3 (10%). No incluir más de 15 características ni menos de 5, justificar la selección (5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para todos los datos\n",
    "all_files = datos_diagnostics['FileName'].tolist()\n",
    "df,datos_II_ecg=cargar_datos(all_files[:8],1)\n",
    "sujetos=datos_II_ecg.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para obtener solo las filas de los archivos en selected_files\n",
    "selected_data_all = datos_diagnostics[datos_diagnostics['FileName'].isin(all_files)]\n",
    "\n",
    "# Crear un diccionario con 'FileName' como clave y 'Rhythm' como valor para fácil acceso\n",
    "file_rhythm_all = dict(zip(selected_data_all['FileName'], selected_data_all['Rhythm']))\n",
    "\n",
    "df_ECG = pd.DataFrame(columns=[\"Registro\", \"Estado\",\"VentricularRate\",\"AtrialRate\",\"QRSCount\",\"QRSDuration\",\"QTInterval\",\"qt_corrected\",\"systole_duration\",\"diastole_duration\",\"systole_diastole_ratio\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for archivo in all_files:\n",
    "for archivo in sujetos:\n",
    "    dato=datos_II_ecg[archivo][1:].astype(float)  # Convertir a tipo numérico si es necesario\n",
    "    nombre=\"MUSE_20180115_122301_43000\"\n",
    "    estado=\"SB\"\n",
    "    # Procesar la señal ECG\n",
    "    Processed_signals, info = nk.ecg_process(dato, sampling_rate=500)\n",
    "\n",
    "    # Extraer los picos R de la señal ECG y obtener promedio para obtener la frecuencia ventricular\n",
    "    picos_R = info['ECG_R_Peaks']\n",
    "    # Calcular los intervalos RR (en segundos) dividiendo por la frecuencia de muestreo\n",
    "    intervalos_RR = np.diff(picos_R) / fs\n",
    "    # Calcular la frecuencia ventricular promedio (latidos por minuto)\n",
    "    VentricularRate  = 60 / np.mean(intervalos_RR)\n",
    "\n",
    "    # Extraer los picos P de la señal ECG\n",
    "    picos_P = np.array(info['ECG_P_Peaks'])\n",
    "    # Filtrar NaN de los picos P para evitar errores de cálculo\n",
    "    # picos_P_limpios = picos_P[~np.isnan(picos_P)]\n",
    "    picos_P_limpios = pd.Series(picos_P).interpolate().values #se cambian los NaN interpolandolos. Esto es útil para señales fisiológicas, ya que los datos suelen ser continuos.\n",
    "    # Calcular la frecuencia auricular promedio (latidos por minuto)\n",
    "    AtrialRate = 60 / np.mean(np.diff(picos_P_limpios) / 500)\n",
    "\n",
    "    # Cantidad de complejos QRS\n",
    "    QRSCount = len(picos_R)  \n",
    "\n",
    "    # Obtener duración del complejo QRS\n",
    "    # Obtener el inicio y final del QRS\n",
    "    Q_onsets = np.array(info[\"ECG_Q_Peaks\"])  # Convertir a numpy array\n",
    "    Q_offsets = np.array(info[\"ECG_R_Offsets\"])  # Convertir a numpy array\n",
    "    # Calcular la duración promedio del QRS\n",
    "    QRS_durations = (Q_offsets - Q_onsets) / fs\n",
    "    QRSDuration = np.mean(QRS_durations)\n",
    "\n",
    "    # Intervalo onda QT\n",
    "    # Obtener el final de la onda T\n",
    "    T_offsets = info[\"ECG_T_Offsets\"]\n",
    "    # Calcular el intervalo QT promedio\n",
    "    QT_intervals = (T_offsets - Q_onsets) / fs\n",
    "    QTInterval = np.mean(QT_intervals)\n",
    "\n",
    "    # Calcular QT corregido usando la fórmula de Bazett,\n",
    "    # El QT corregido (QTc) ajusta el intervalo QT en función de la frecuencia cardíaca.\n",
    "    qt_corrected = QTInterval / np.sqrt(np.mean(intervalos_RR))\n",
    "    qt_corrected= np.mean(qt_corrected)\n",
    "\n",
    "    # Extraer las fases ventriculares (sístole y diástole)\n",
    "    fases_ventriculares = Processed_signals[\"ECG_Phase_Ventricular\"].values\n",
    "    # Contar las muestras en cada fase\n",
    "    conteo_sistole = len(fases_ventriculares[fases_ventriculares == 1])\n",
    "    conteo_diastole = len(fases_ventriculares[fases_ventriculares == 0])\n",
    "    # Duración promedio de cada fase\n",
    "    systole_duration = conteo_sistole / fs  # En segundos\n",
    "    diastole_duration = conteo_diastole / fs  # En segundos\n",
    "\n",
    "    # Relación sístole/diástole\n",
    "    systole_diastole_ratio = systole_duration / diastole_duration\n",
    "\n",
    "# Obtener el nombre del sujeto (sin extensión .csv)\n",
    "    nombre_sujeto = archivo[:-4] #Registro\n",
    "\n",
    "    estado = file_rhythm_all[archivo] #Estado\n",
    "\n",
    "    df_ECG = pd.concat([df_ECG,\n",
    "                    pd.DataFrame({'Registro': nombre_sujeto,\n",
    "                                    'Estado': estado,\n",
    "                                    \"VentricularRate\": VentricularRate,\n",
    "                                    \"AtrialRate\": AtrialRate,\n",
    "                                    \"QRSCount\":QRSCount,\n",
    "                                    \"QRSDuration\":QRSDuration,\n",
    "                                    \"QTInterval\":QTInterval,\n",
    "                                    \"qt_corrected\":qt_corrected,\n",
    "                                    \"systole_duration\":systole_duration,\n",
    "                                    \"diastole_duration\":diastole_duration,\n",
    "                                    \"systole_diastole_ratio\":systole_diastole_ratio},\n",
    "                                index=[0])\n",
    "                    ],\n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registro</th>\n",
       "      <th>Estado</th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>qt_corrected</th>\n",
       "      <th>systole_duration</th>\n",
       "      <th>diastole_duration</th>\n",
       "      <th>systole_diastole_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_2</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>117.085863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.930</td>\n",
       "      <td>6.492</td>\n",
       "      <td>0.451325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_2</td>\n",
       "      <td>SB</td>\n",
       "      <td>51.698671</td>\n",
       "      <td>51.673228</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.978</td>\n",
       "      <td>5.518</td>\n",
       "      <td>0.539688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180113_121940_4</td>\n",
       "      <td>SB</td>\n",
       "      <td>53.309640</td>\n",
       "      <td>53.297801</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.170</td>\n",
       "      <td>5.836</td>\n",
       "      <td>0.543180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180112_120347_7</td>\n",
       "      <td>SB</td>\n",
       "      <td>56.617127</td>\n",
       "      <td>56.590427</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.126</td>\n",
       "      <td>5.698</td>\n",
       "      <td>0.548614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180114_075026_6</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>95.703956</td>\n",
       "      <td>95.379398</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.508</td>\n",
       "      <td>4.898</td>\n",
       "      <td>0.920376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSE_20180114_075128_9</td>\n",
       "      <td>SB</td>\n",
       "      <td>58.504875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.218</td>\n",
       "      <td>6.338</td>\n",
       "      <td>0.507731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MUSE_20180118_174026_4</td>\n",
       "      <td>SB</td>\n",
       "      <td>58.422590</td>\n",
       "      <td>58.365759</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.288</td>\n",
       "      <td>5.294</td>\n",
       "      <td>0.621080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MUSE_20180115_125443_2</td>\n",
       "      <td>SB</td>\n",
       "      <td>55.414454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.524</td>\n",
       "      <td>5.532</td>\n",
       "      <td>0.637021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Registro Estado  VentricularRate  AtrialRate QRSCount  \\\n",
       "0  MUSE_20180113_171327_2   AFIB       117.085863         NaN       19   \n",
       "1  MUSE_20180112_073319_2     SB        51.698671   51.673228        8   \n",
       "2  MUSE_20180113_121940_4     SB        53.309640   53.297801        9   \n",
       "3  MUSE_20180112_120347_7     SB        56.617127   56.590427        9   \n",
       "4  MUSE_20180114_075026_6   AFIB        95.703956   95.379398       16   \n",
       "5  MUSE_20180114_075128_9     SB        58.504875         NaN       10   \n",
       "6  MUSE_20180118_174026_4     SB        58.422590   58.365759        9   \n",
       "7  MUSE_20180115_125443_2     SB        55.414454         NaN        9   \n",
       "\n",
       "   QRSDuration  QTInterval  qt_corrected  systole_duration  diastole_duration  \\\n",
       "0          NaN         NaN           NaN             2.930              6.492   \n",
       "1          NaN         NaN           NaN             2.978              5.518   \n",
       "2          NaN         NaN           NaN             3.170              5.836   \n",
       "3          NaN         NaN           NaN             3.126              5.698   \n",
       "4          NaN         NaN           NaN             4.508              4.898   \n",
       "5          NaN         NaN           NaN             3.218              6.338   \n",
       "6          NaN         NaN           NaN             3.288              5.294   \n",
       "7          NaN         NaN           NaN             3.524              5.532   \n",
       "\n",
       "   systole_diastole_ratio  \n",
       "0                0.451325  \n",
       "1                0.539688  \n",
       "2                0.543180  \n",
       "3                0.548614  \n",
       "4                0.920376  \n",
       "5                0.507731  \n",
       "6                0.621080  \n",
       "7                0.637021  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Registro', 'Estado', 'VentricularRate', 'AtrialRate', 'QRSCount',\n",
       "       'QRSDuration', 'QTInterval', 'qt_corrected', 'systole_duration',\n",
       "       'diastole_duration', 'systole_diastole_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ECG.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Crear una rutina que aplique sobre todos los archivos de la base de datos la rutina 5 y almacene los resultados en un dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_base_datos_p3=\"./datos/Dataframe_P3.xlsx\"\n",
    "df_p3 = pd.read_excel(ruta_base_datos_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_diagnostics = datos_diagnostics.rename(columns={'FileName': 'Registro'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnostics_2merge= datos_diagnostics[[\"Registro\",\"Beat\",\"PatientAge\",\"Gender\"]]\n",
    "df_p3_2merge= df_p3[[\"Registro\",\"fMP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registro</th>\n",
       "      <th>Beat</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_27000</td>\n",
       "      <td>RBBB TWC</td>\n",
       "      <td>85</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_29000</td>\n",
       "      <td>TWC</td>\n",
       "      <td>59</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180113_121940_44000</td>\n",
       "      <td>NONE</td>\n",
       "      <td>66</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSE_20180112_120347_79000</td>\n",
       "      <td>NONE</td>\n",
       "      <td>46</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MUSE_20180114_075026_69000</td>\n",
       "      <td>TWC</td>\n",
       "      <td>80</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Registro      Beat  PatientAge  Gender\n",
       "0  MUSE_20180113_171327_27000  RBBB TWC          85    MALE\n",
       "1  MUSE_20180112_073319_29000       TWC          59  FEMALE\n",
       "3  MUSE_20180113_121940_44000      NONE          66    MALE\n",
       "5  MUSE_20180112_120347_79000      NONE          46  FEMALE\n",
       "6  MUSE_20180114_075026_69000       TWC          80  FEMALE"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diagnostics_2merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registro</th>\n",
       "      <th>fMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_2</td>\n",
       "      <td>0.488281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_2</td>\n",
       "      <td>0.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180113_121940_4</td>\n",
       "      <td>3.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180112_120347_7</td>\n",
       "      <td>0.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180114_075026_6</td>\n",
       "      <td>4.394531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Registro       fMP\n",
       "0  MUSE_20180113_171327_2  0.488281\n",
       "1  MUSE_20180112_073319_2  0.976562\n",
       "2  MUSE_20180113_121940_4  3.417969\n",
       "3  MUSE_20180112_120347_7  0.976562\n",
       "4  MUSE_20180114_075026_6  4.394531"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p3_2merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registro</th>\n",
       "      <th>Estado</th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>qt_corrected</th>\n",
       "      <th>systole_duration</th>\n",
       "      <th>diastole_duration</th>\n",
       "      <th>systole_diastole_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_2</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>117.085863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.930</td>\n",
       "      <td>6.492</td>\n",
       "      <td>0.451325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_2</td>\n",
       "      <td>SB</td>\n",
       "      <td>51.698671</td>\n",
       "      <td>51.673228</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.978</td>\n",
       "      <td>5.518</td>\n",
       "      <td>0.539688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180113_121940_4</td>\n",
       "      <td>SB</td>\n",
       "      <td>53.309640</td>\n",
       "      <td>53.297801</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.170</td>\n",
       "      <td>5.836</td>\n",
       "      <td>0.543180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180112_120347_7</td>\n",
       "      <td>SB</td>\n",
       "      <td>56.617127</td>\n",
       "      <td>56.590427</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.126</td>\n",
       "      <td>5.698</td>\n",
       "      <td>0.548614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180114_075026_6</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>95.703956</td>\n",
       "      <td>95.379398</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.508</td>\n",
       "      <td>4.898</td>\n",
       "      <td>0.920376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSE_20180114_075128_9</td>\n",
       "      <td>SB</td>\n",
       "      <td>58.504875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.218</td>\n",
       "      <td>6.338</td>\n",
       "      <td>0.507731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MUSE_20180118_174026_4</td>\n",
       "      <td>SB</td>\n",
       "      <td>58.422590</td>\n",
       "      <td>58.365759</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.288</td>\n",
       "      <td>5.294</td>\n",
       "      <td>0.621080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MUSE_20180115_125443_2</td>\n",
       "      <td>SB</td>\n",
       "      <td>55.414454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.524</td>\n",
       "      <td>5.532</td>\n",
       "      <td>0.637021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Registro Estado  VentricularRate  AtrialRate QRSCount  \\\n",
       "0  MUSE_20180113_171327_2   AFIB       117.085863         NaN       19   \n",
       "1  MUSE_20180112_073319_2     SB        51.698671   51.673228        8   \n",
       "2  MUSE_20180113_121940_4     SB        53.309640   53.297801        9   \n",
       "3  MUSE_20180112_120347_7     SB        56.617127   56.590427        9   \n",
       "4  MUSE_20180114_075026_6   AFIB        95.703956   95.379398       16   \n",
       "5  MUSE_20180114_075128_9     SB        58.504875         NaN       10   \n",
       "6  MUSE_20180118_174026_4     SB        58.422590   58.365759        9   \n",
       "7  MUSE_20180115_125443_2     SB        55.414454         NaN        9   \n",
       "\n",
       "   QRSDuration  QTInterval  qt_corrected  systole_duration  diastole_duration  \\\n",
       "0          NaN         NaN           NaN             2.930              6.492   \n",
       "1          NaN         NaN           NaN             2.978              5.518   \n",
       "2          NaN         NaN           NaN             3.170              5.836   \n",
       "3          NaN         NaN           NaN             3.126              5.698   \n",
       "4          NaN         NaN           NaN             4.508              4.898   \n",
       "5          NaN         NaN           NaN             3.218              6.338   \n",
       "6          NaN         NaN           NaN             3.288              5.294   \n",
       "7          NaN         NaN           NaN             3.524              5.532   \n",
       "\n",
       "   systole_diastole_ratio  \n",
       "0                0.451325  \n",
       "1                0.539688  \n",
       "2                0.543180  \n",
       "3                0.548614  \n",
       "4                0.920376  \n",
       "5                0.507731  \n",
       "6                0.621080  \n",
       "7                0.637021  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ECG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2train=df_ECG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2train = df_2train.merge(df_diagnostics_2merge, on='Registro', how='left')\n",
    "df_2train = df_2train.merge(df_p3_2merge, on='Registro', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registro</th>\n",
       "      <th>Estado</th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>qt_corrected</th>\n",
       "      <th>systole_duration</th>\n",
       "      <th>diastole_duration</th>\n",
       "      <th>systole_diastole_ratio</th>\n",
       "      <th>Beat_x</th>\n",
       "      <th>PatientAge_x</th>\n",
       "      <th>Gender_x</th>\n",
       "      <th>fMP_x</th>\n",
       "      <th>Beat_y</th>\n",
       "      <th>PatientAge_y</th>\n",
       "      <th>Gender_y</th>\n",
       "      <th>fMP_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_2</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>117.085863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.930</td>\n",
       "      <td>6.492</td>\n",
       "      <td>0.451325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_2</td>\n",
       "      <td>SB</td>\n",
       "      <td>51.698671</td>\n",
       "      <td>51.673228</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.978</td>\n",
       "      <td>5.518</td>\n",
       "      <td>0.539688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180113_121940_4</td>\n",
       "      <td>SB</td>\n",
       "      <td>53.309640</td>\n",
       "      <td>53.297801</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.170</td>\n",
       "      <td>5.836</td>\n",
       "      <td>0.543180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.417969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180112_120347_7</td>\n",
       "      <td>SB</td>\n",
       "      <td>56.617127</td>\n",
       "      <td>56.590427</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.126</td>\n",
       "      <td>5.698</td>\n",
       "      <td>0.548614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180114_075026_6</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>95.703956</td>\n",
       "      <td>95.379398</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.508</td>\n",
       "      <td>4.898</td>\n",
       "      <td>0.920376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.394531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.394531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSE_20180114_075128_9</td>\n",
       "      <td>SB</td>\n",
       "      <td>58.504875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.218</td>\n",
       "      <td>6.338</td>\n",
       "      <td>0.507731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MUSE_20180118_174026_4</td>\n",
       "      <td>SB</td>\n",
       "      <td>58.422590</td>\n",
       "      <td>58.365759</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.288</td>\n",
       "      <td>5.294</td>\n",
       "      <td>0.621080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MUSE_20180115_125443_2</td>\n",
       "      <td>SB</td>\n",
       "      <td>55.414454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.524</td>\n",
       "      <td>5.532</td>\n",
       "      <td>0.637021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Registro Estado  VentricularRate  AtrialRate QRSCount  \\\n",
       "0  MUSE_20180113_171327_2   AFIB       117.085863         NaN       19   \n",
       "1  MUSE_20180112_073319_2     SB        51.698671   51.673228        8   \n",
       "2  MUSE_20180113_121940_4     SB        53.309640   53.297801        9   \n",
       "3  MUSE_20180112_120347_7     SB        56.617127   56.590427        9   \n",
       "4  MUSE_20180114_075026_6   AFIB        95.703956   95.379398       16   \n",
       "5  MUSE_20180114_075128_9     SB        58.504875         NaN       10   \n",
       "6  MUSE_20180118_174026_4     SB        58.422590   58.365759        9   \n",
       "7  MUSE_20180115_125443_2     SB        55.414454         NaN        9   \n",
       "\n",
       "   QRSDuration  QTInterval  qt_corrected  systole_duration  diastole_duration  \\\n",
       "0          NaN         NaN           NaN             2.930              6.492   \n",
       "1          NaN         NaN           NaN             2.978              5.518   \n",
       "2          NaN         NaN           NaN             3.170              5.836   \n",
       "3          NaN         NaN           NaN             3.126              5.698   \n",
       "4          NaN         NaN           NaN             4.508              4.898   \n",
       "5          NaN         NaN           NaN             3.218              6.338   \n",
       "6          NaN         NaN           NaN             3.288              5.294   \n",
       "7          NaN         NaN           NaN             3.524              5.532   \n",
       "\n",
       "   systole_diastole_ratio Beat_x  PatientAge_x Gender_x     fMP_x Beat_y  \\\n",
       "0                0.451325    NaN           NaN      NaN  0.488281    NaN   \n",
       "1                0.539688    NaN           NaN      NaN  0.976562    NaN   \n",
       "2                0.543180    NaN           NaN      NaN  3.417969    NaN   \n",
       "3                0.548614    NaN           NaN      NaN  0.976562    NaN   \n",
       "4                0.920376    NaN           NaN      NaN  4.394531    NaN   \n",
       "5                0.507731    NaN           NaN      NaN  0.976562    NaN   \n",
       "6                0.621080    NaN           NaN      NaN  0.976562    NaN   \n",
       "7                0.637021    NaN           NaN      NaN  0.976562    NaN   \n",
       "\n",
       "   PatientAge_y Gender_y     fMP_y  \n",
       "0           NaN      NaN  0.488281  \n",
       "1           NaN      NaN  0.976562  \n",
       "2           NaN      NaN  3.417969  \n",
       "3           NaN      NaN  0.976562  \n",
       "4           NaN      NaN  4.394531  \n",
       "5           NaN      NaN  0.976562  \n",
       "6           NaN      NaN  0.976562  \n",
       "7           NaN      NaN  0.976562  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Código y análisis de resultados, donde se discutan por los menos tres diferentes arquitecturas de red (10%) y las matrices de confusión obtenidas (10%), de una red neuronal que permita la clasificación de las dos patologías cardiacas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df_2train # Dataframe con todas las columnas y caracteristicas para entrenar\n",
    "df_training = df_training.iloc[:, :100] #Dataframe de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar la columna objetivo\n",
    "target_column = 'Estado'\n",
    "X = df_training.drop(columns=[target_column])  # Datos de entrada\n",
    "y = df_training[target_column]  # Columna objetivo\n",
    "num_layers=len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de X\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Pipeline para procesar columnas numéricas y categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preparados para entrenamiento y evaluación.\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en entrenamiento y evaluación\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Aplicar el preprocesamiento\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_eval = preprocessor.transform(X_eval)\n",
    "\n",
    "# Convertir la columna objetivo a one-hot encoding\n",
    "encoder = OneHotEncoder()\n",
    "y_train = encoder.fit_transform(y_train.values.reshape(-1, 1)).toarray()\n",
    "y_eval = encoder.transform(y_eval.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(\"Datos preparados para entrenamiento y evaluación.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.1667 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.8333 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8333 - loss: 0.6918 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8333 - loss: 0.6912 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.8333 - loss: 0.6905 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8333 - loss: 0.6898 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8333 - loss: 0.6892 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8333 - loss: 0.6885 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8333 - loss: 0.6878 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8333 - loss: 0.6872 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8333 - loss: 0.6865 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8333 - loss: 0.6859 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8333 - loss: 0.6852 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8333 - loss: 0.6846 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8333 - loss: 0.6839 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8333 - loss: 0.6833 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8333 - loss: 0.6826 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8333 - loss: 0.6820 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.8333 - loss: 0.6813 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.8333 - loss: 0.6807 - val_accuracy: 0.5000 - val_loss: 0.6933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x291ce6d19d0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP\n",
    "def build_mlp(input_shape, output_shape,num_layers):\n",
    "    model = Sequential([\n",
    "        Dense(num_layers, activation='relu', input_shape=input_shape),\n",
    "        Dense(math.ceil(num_layers/2), activation='relu'),\n",
    "        Dense(output_shape, activation='softmax')  # Salida para clasificación\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# def build_mlp(input_shape, output_shape):\n",
    "#     model = Sequential([\n",
    "#         Dense(64, activation='relu', input_shape=input_shape),\n",
    "#         Dense(32, activation='relu'),\n",
    "#         Dense(output_shape, activation='softmax')  # Salida para clasificación\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "mlp_model = build_mlp((X_train.shape[1],), y_train.shape[1],num_layers=num_layers)\n",
    "mlp_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_eval, y_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo MLP: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de evaluación\n",
    "mpl_loss, mlp_accuracy = mlp_model.evaluate(X_eval, y_eval, verbose=0)\n",
    "print(f\"Exactitud del modelo MLP: {mlp_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CNN\n",
    "def build_cnn(input_shape, output_shape,num_layers):\n",
    "    model = Sequential([\n",
    "        Conv1D(num_layers, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(math.ceil(num_layers/2), activation='relu'),\n",
    "        Dense(output_shape, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# def build_cnn(input_shape, output_shape):\n",
    "#     model = Sequential([\n",
    "#         Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "#         MaxPooling1D(pool_size=2),\n",
    "#         Flatten(),\n",
    "#         Dense(64, activation='relu'),\n",
    "#         Dense(output_shape, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "cnn_model = build_cnn((X_train.shape[1], 1), y_train.shape[1],num_layers=num_layers)\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "# cnn_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de evaluación\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_eval, y_eval, verbose=0)\n",
    "print(f\"Exactitud del modelo CNN: {cnn_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(input_shape, output_shape,num_layers):\n",
    "    model = Sequential([\n",
    "        LSTM(num_layers, activation='tanh', input_shape=input_shape),\n",
    "        Dense(math.ceil(num_layers/2), activation='relu'),\n",
    "        Dense(output_shape, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "# def build_lstm(input_shape, output_shape):\n",
    "#     model = Sequential([\n",
    "#         LSTM(50, activation='tanh', input_shape=input_shape),\n",
    "#         Dense(64, activation='relu'),\n",
    "#         Dense(output_shape, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# Adaptar datos para LSTM (similar a CNN)\n",
    "lstm_model = build_lstm((X_train.shape[1], 1), y_train.shape[1])\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "# lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_eval, y_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de evaluación\n",
    "lstm_loss, lstm_accuracy = cnn_model.evaluate(X_eval, y_eval, verbose=0)\n",
    "print(f\"Exactitud del modelo LSTM: {lstm_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Consultar cómo funciona, realizar y discutir un ejemplo con los datos, del algoritmo de K means (10%) y máquinas de soporte vectorial (SVM) (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Consultar por lo menos tres equipos comerciales traen ya incorporados algoritmos de ayuda diagnóstica a partir de señales EKG (5%) y discutir brevemente las funcionalidades desde la teoría vista en el curso (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de datos \n",
    "### (En caso de ser necesario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_wavelet(signal_data, wavelet='db4', nivel=4):\n",
    "    coeffs = pywt.wavedec(signal_data, wavelet, level=nivel)\n",
    "    umbral = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "    coeffs = [pywt.threshold(c, umbral, mode='soft') for c in coeffs]\n",
    "    return pywt.waverec(coeffs,wavelet)\n",
    "\n",
    "# Para cada señal extraer la frecuencia que contiene la máxima potencia y Gráfiquela \n",
    "def obtener_frecuencia_maxima_potencia(df, fs=1000):\n",
    "    nperseg = 1024 \n",
    "    noverlap = int(nperseg / 2)  \n",
    "    ventana = np.hamming(nperseg)  \n",
    "    \n",
    "    # Calcular la densidad espectral de potencia utilizando Welch\n",
    "    frecuencias, potencia = welch(df, fs=fs,window=ventana, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "    # Encontrar la frecuencia con la máxima potencia\n",
    "    indice_max_potencia = potencia.argmax()\n",
    "    frecuencia_max = frecuencias[indice_max_potencia]\n",
    "\n",
    "    return frecuencia_max\n",
    "\n",
    "# Flujo 2: Detrend, Filtro wavelet, Filtro pasabajas\n",
    "def flujo_2(data,fs = 1000 ):\n",
    "    # Paso 1: Detrend\n",
    "    data_detrended = signal.detrend(data)\n",
    "    \n",
    "    # Paso 2: Filtro wavelet\n",
    "    data_denoised=filtro_wavelet(data_detrended, wavelet='db4', nivel=4)\n",
    "\n",
    "    # Paso 3: Filtro pasabajas IIR a 50 Hz\n",
    "    cutoff = 50  # Frecuencia de corte en Hz\n",
    "    sos = signal.butter(4, cutoff, btype='lowpass', fs=fs, output='sos')\n",
    "    data_lowpass = signal.sosfilt(sos, data_denoised)\n",
    "    \n",
    "    return data_lowpass\n",
    "\n",
    "def flujo_2_ajustado(data,fs = 1000 ):\n",
    "    cutoff= 0.5  # Frecuencia de corte en Hz\n",
    "    order=4\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    data_f=filtfilt(b, a, data)\n",
    "    \n",
    "    # Paso 1: Detrend    \n",
    "    data_detrended = signal.detrend(data_f)\n",
    "    \n",
    "    # Paso 2: Filtro wavelet\n",
    "    data_denoised=filtro_wavelet(data_detrended, wavelet='db4', nivel=4)\n",
    "\n",
    "    # Paso 3: Filtro pasabajas IIR a 50 Hz\n",
    "    cutoff = 50  # Frecuencia de corte en Hz\n",
    "    sos = signal.butter(4, cutoff, btype='lowpass', fs=fs, output='sos')\n",
    "    data_lowpass = signal.sosfilt(sos, data_denoised)\n",
    "    \n",
    "    return data_lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = datos_diagnostics['FileName'].tolist()\n",
    "df,datos_II=cargar_datos(all_files,1)\n",
    "sujetos=datos_II.keys()\n",
    "\n",
    "\n",
    "# Crear un DataFrame vacío para almacenar los resultados\n",
    "df_resultados_flujo = pd.DataFrame(columns=[\"Registro\", \"Estado\", \"fMP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para obtener solo las filas de los archivos en selected_files\n",
    "selected_data_all = datos_diagnostics[datos_diagnostics['FileName'].isin(all_files)]\n",
    "\n",
    "# Crear un diccionario con 'FileName' como clave y 'Rhythm' como valor para fácil acceso\n",
    "file_rhythm_all = dict(zip(selected_data_all['FileName'], selected_data_all['Rhythm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for archivo in all_files:\n",
    "for archivo in sujetos:\n",
    "\n",
    "    data=datos_II[archivo][1:].astype(float)  # Convertir a tipo numérico si es necesario\n",
    "    # tiempo = np.arange(0, selected_files[archivo].shape/fs,1/fs)\n",
    "    tiempo= np.arange(0, data.shape[0]/fs,1/fs)\n",
    "\n",
    "# Obtener el nombre del sujeto (sin extensión .csv)\n",
    "    nombre_sujeto = archivo[:-4] #Registro\n",
    "\n",
    "# Procesar los archivos\n",
    "    resultados_proceso=flujo_2_ajustado(data,fs)\n",
    "\n",
    "    estado = file_rhythm_all[archivo] #Estado\n",
    "    \n",
    "    F_max=obtener_frecuencia_maxima_potencia(resultados_proceso,fs)\n",
    "    \n",
    "    df_resultados_flujo = pd.concat([df_resultados_flujo,\n",
    "                    pd.DataFrame({'Registro': nombre_sujeto,\n",
    "                                    'Estado': estado,\n",
    "                                    'fMP': F_max},\n",
    "                                index=[0])\n",
    "                    ],\n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resultados_flujo.to_excel(\"Dataframe_P3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codigo para probar modelos con datos aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos simulados\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "timesteps = 100  # Longitud de la señal (100 puntos de tiempo)\n",
    "\n",
    "# Simulación de señales ECG\n",
    "X = np.random.normal(0, 1, (n_samples, timesteps, 1))  # Señales con ruido\n",
    "y = np.random.randint(0, 2, n_samples)  # Etiquetas binarias (0: SB, 1: AFIB)\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las señales\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, timesteps)).reshape(-1, timesteps, 1)\n",
    "X_test = scaler.transform(X_test.reshape(-1, timesteps)).reshape(-1, timesteps, 1)\n",
    "\n",
    "# Convertir etiquetas a formato categórico\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "[1] "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
